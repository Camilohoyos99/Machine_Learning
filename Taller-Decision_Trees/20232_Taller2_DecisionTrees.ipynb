{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1yqs8ZAAgoF"
   },
   "source": [
    "#Taller: Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tw1mQlCZU5lX"
   },
   "source": [
    "En este taller analizaremos aspectos de árboles de decisión para varios conjuntos de datos. El primero es el [Play tennis dataset](https://www.kaggle.com/datasets/fredericobreno/play-tennis). El segundo es el [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). El tercero es el [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). El cuarto es [Hitters](https://www.kaggle.com/datasets/floser/hitters).\n",
    "\n",
    "El taller consiste en realizar todas las tareas numeradas del 1 al 13.\n",
    "Cargar el cuaderno ejecutado y guardado en formato .ipynb y en formato .HTML a más tardar el martes 22 de agosto a las 11:00am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "vkouMudDAiHb"
   },
   "outputs": [],
   "source": [
    "#Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHrRRlMqZSAh"
   },
   "source": [
    "## Tennis Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAqHm391W-Wp"
   },
   "source": [
    "En primer lugar, cargar y leer el conjunto de datos Play Tennis, e imprimir todas sus filas (son pocas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "n8AYV6tGXQLB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind</th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     outlook  temp humidity    wind play\n",
       "0      Sunny   Hot     High    Weak   No\n",
       "1      Sunny   Hot     High  Strong   No\n",
       "2   Overcast   Hot     High    Weak  Yes\n",
       "3       Rain  Mild     High    Weak  Yes\n",
       "4       Rain  Cool   Normal    Weak  Yes\n",
       "5       Rain  Cool   Normal  Strong   No\n",
       "6   Overcast  Cool   Normal  Strong  Yes\n",
       "7      Sunny  Mild     High    Weak   No\n",
       "8      Sunny  Cool   Normal    Weak  Yes\n",
       "9       Rain  Mild   Normal    Weak  Yes\n",
       "10     Sunny  Mild   Normal  Strong  Yes\n",
       "11  Overcast  Mild     High  Strong  Yes\n",
       "12  Overcast   Hot   Normal    Weak  Yes\n",
       "13      Rain  Mild     High  Strong   No"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leer el Play tennis dataset.\n",
    "#Mostrar todas sus filas.\n",
    "df = pd.read_csv('tennis.csv')\n",
    "df1 = df\n",
    "df.pop('day')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fggb798pAbx"
   },
   "source": [
    "El clasificador de árboles de decisión de SKLearn recibe únicamente atributos numéricos. Dado que todos los atributos de este dataset son categorías determinadas por datos tipo *string* necesitamos codificar estas categorías con el método one hot encoding, el cual hemos discutido en clase (si no lo recuerda, puede preguntarme).\n",
    "Una forma de hacer esto en Python es utilizando la función *get_dummies* de Pandas.\n",
    "\n",
    "El parámetro *drop_first=True* remueve una de las columnas generadas en cada variable, pues ésta realmente reundaría con las demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "xV2j0zVqpEzP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlook_Rain</th>\n",
       "      <th>outlook_Sunny</th>\n",
       "      <th>temp_Hot</th>\n",
       "      <th>temp_Mild</th>\n",
       "      <th>humidity_Normal</th>\n",
       "      <th>wind_Weak</th>\n",
       "      <th>play_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlook_Rain  outlook_Sunny  temp_Hot  temp_Mild  humidity_Normal  \\\n",
       "0              0              1         1          0                0   \n",
       "1              0              1         1          0                0   \n",
       "2              0              0         1          0                0   \n",
       "3              1              0         0          1                0   \n",
       "4              1              0         0          0                1   \n",
       "5              1              0         0          0                1   \n",
       "6              0              0         0          0                1   \n",
       "7              0              1         0          1                0   \n",
       "8              0              1         0          0                1   \n",
       "9              1              0         0          1                1   \n",
       "10             0              1         0          1                1   \n",
       "11             0              0         0          1                0   \n",
       "12             0              0         1          0                1   \n",
       "13             1              0         0          1                0   \n",
       "\n",
       "    wind_Weak  play_Yes  \n",
       "0           1         0  \n",
       "1           0         0  \n",
       "2           1         1  \n",
       "3           1         1  \n",
       "4           1         1  \n",
       "5           0         0  \n",
       "6           0         1  \n",
       "7           1         0  \n",
       "8           1         1  \n",
       "9           1         1  \n",
       "10          0         1  \n",
       "11          0         1  \n",
       "12          1         1  \n",
       "13          0         0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df,drop_first=True)# codifica los datos que son labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sunny\n",
       "1        Sunny\n",
       "2     Overcast\n",
       "3         Rain\n",
       "4         Rain\n",
       "5         Rain\n",
       "6     Overcast\n",
       "7        Sunny\n",
       "8        Sunny\n",
       "9         Rain\n",
       "10       Sunny\n",
       "11    Overcast\n",
       "12    Overcast\n",
       "13        Rain\n",
       "Name: outlook, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['outlook']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpsR6_szpJV8"
   },
   "source": [
    "Imprima el dataset codificado y asegúrese de que es clara la función get_dummies. Por ejemplo, ¿cómo habría quedado el dataset si no le hubieramos dado el valor de verdadero al parámetro drop_first?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Sin este parametro se crea un dummies para todo el data set, lo que significa que cada variable va a quedar con una codificación distinta, al usar el parametro drop_first=True \"elimina\" el primer bloque de codificación de cada atributo, pero este queda representado por la codificación 0,0,0 .... ( así hasta la cantidad diferente de elemnentos de un atributo), por lo que se evíta tener información \"redundante\" y evíta   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCukLOIYpWdL"
   },
   "source": [
    "#### Cálculo de la ganancia de información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WklVjMXtXXEc"
   },
   "source": [
    "1. De acuerdo a lo visto en clase, cacular la ganancia de información  para cada uno de los atributos del dataset:\n",
    "$Gain(S,A)=Ent(S)-\\sum_{v\\in values(A)}\\frac{|S_v|}{|S|}Ent(S_v)$.\n",
    "\n",
    " ¿Cuál sería el mejor atributo para comenzar el árbol?\n",
    "Observación: Puede hacer sus cálculos a mano y adjuntar una imagen de los mismos, o programar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1y-81dUfpcfp"
   },
   "source": [
    "#### Construcción de un primer modelo de árbol de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0gDfxfirrT2"
   },
   "source": [
    "Para el casos de clasificación, como lo es el del dataset Play tennis, utilizaremos el algoritmo *DecisionTreeClassifier* De SKLearn. Como el dataset es tan pequeño, en este primer caso construiremos el modelo cutilizando el dataset completo como conjunto de entrenamiento.\n",
    "\n",
    "2. Defina como *y* la columna de la variable objetivo, y defina como *X* el dataset *sin* la columna de la varible objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "JQ3jJEQmssCp"
   },
   "outputs": [],
   "source": [
    "# Definir X,y\n",
    "def entropy(S, sv = None): # S va a funcionar como una columna\n",
    "                #caso 1 le vamos a pasar la columna respuesta\n",
    "    if sv ==None:\n",
    "        valores = S.unique()\n",
    "        cuenta = np.array([(S == val).sum() for val in valores])\n",
    "        cuenta = cuenta/len(S) \n",
    "        res =[p * np.log2(p) for p in cuenta ]\n",
    "        res = -1 * sum(res)\n",
    "    else:\n",
    "        valores = S.unique()\n",
    "        cuenta = np.array([(sv == val).sum() for val in valores])\n",
    "        cuenta = cuenta/len(S) \n",
    "        res =[p * np.log2(p) for p in cuenta ]\n",
    "        res = -1 * sum(res)\n",
    "        \n",
    "    return res\n",
    "def gain(S,A):\n",
    "    first = entropy(S)\n",
    "    val_atributos = A.unique()\n",
    "    cuenta = np.array(([a == val_atributos]).sum() for a in val_atributos)\n",
    "    second = sum(cuenta/len(A))\n",
    "    third = entropy(A)\n",
    "    res = first - (second * third)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = df1['play']\n",
    "sv = (df1['outlook'] == 'Sunny') & (S == 'Yes')\n",
    "sv.sum() #nos quedamos en el púnto en que la segunda entropia se alcula con sv, el cual para la entropia es el numero de \n",
    "#\" aciertos de una determinada varisable \", con esta suma tenemos el numero de TRUE de la condicion por lo que nos faltaría conocer el numero de NO\n",
    "# y una vez hecho esto calcular la probailidad de cada una para la entropia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSCWlZEBsJsk"
   },
   "outputs": [],
   "source": [
    "#Se define el clasificador\n",
    "clf = DecisionTreeClassifier(random_state=0,criterion='entropy')\n",
    "#Se entrena el clasificador\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTQec2ais2M2"
   },
   "source": [
    "A continuación, utilizamos el módulo *pyplot* y la función *plot_tree* para graficar el modelo arrojado por el algoritmo, a saber, el árbol de decisión que se obtiene como salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnhez8hDtOYI"
   },
   "outputs": [],
   "source": [
    "#Se establece el tamaño del diagrama\n",
    "plt.figure(figsize=(40,20))\n",
    "#Se grafica el árbol\n",
    "#filled le da colores a los nodos\n",
    "#feature_names recibe los nombres de los atributos para que se vean en el árbol\n",
    "#class_names imprime la clase de cada hoja en el árbol\n",
    "plot_tree(clf, filled=True, feature_names=list(X.columns),class_names=True)\n",
    "#Título de la gráfica\n",
    "plt.title(\"Decision tree training for training dataset\")\n",
    "#Imprimir la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyqTsVyRvfCS"
   },
   "source": [
    "3. Observe el árbol generado y extraiga la información que éste le brinda. Si hay algo que no comprende de la gráfica puede investigar o preguntar. Escriba la información que encuentre relevante sobre éste árbol. ¿El árbol arrancó por el atributo que usted obtuvo como aquel que aporta más información?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoB5HxK1zoVI"
   },
   "source": [
    "## Árbol de decisión para clasificación del Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxOyJkxRZYYk"
   },
   "source": [
    "En el taller anterior hemos cargado el dataset desde nuestros archivos locales. Sin embargo, SkLearn también nos provee de conjuntos de datos, los cuales podemos cargar directamente utilizando Python.\n",
    "\n",
    "4. Investigue cómo cargar un dataset de SKLearn (se vale ChatGPT! ¿Por qué no?). Cargue el iris dataset. Guardar en X,y las variables de entrada y salida respectivamente, en tipo DataFrame. Separe en conjuntos de entrenamiento y testeo (*X_train, X_test, y_train, y_test*) en una proporción de 70% y 30%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-5c1RApEZDR"
   },
   "outputs": [],
   "source": [
    "#Importar el Iris Dataset usando load_iris de sklearn (ya se importó load_iris). Darle el nombre 'iris'.\n",
    "# Guardar en X,y las variables de entrada y salida respectivamente, en tipo DataFrame.\n",
    "# Usar iris.data, iris.target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv4ayGetbLIn"
   },
   "outputs": [],
   "source": [
    "#Separar en Train y Test set con una proporción de 70%-30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KdHmjeixbk_"
   },
   "source": [
    "5. Definir un clasificador de árbol de decisión con DecisionTreeClassifier de SKlearn. Utilice el criterio 'entropy'. Fije una semilla aleatoria (random_state) para obtener los mismos resultados cada vez que corra el cuderno. Entrenar el Clasificador **con el conjunto de entrenamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YdWECaEdbajR"
   },
   "outputs": [],
   "source": [
    "#Definir un clasificador de árbol de decisión con DecisionTreeClassifier de SKLearn.\n",
    "#Fije un random_state y utilice criterion='entropy'\n",
    "#Entrenarlo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JToFDG6Bdsi1"
   },
   "source": [
    "Es posible medir este modelo usando la métrica *accuracy*: la proporción entre predicciones correctas y el total de predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvLS1_ZPd1iY"
   },
   "outputs": [],
   "source": [
    "#Calcular predicciones para el conjunto de testeo.\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMu-c-hDeec3"
   },
   "source": [
    "\n",
    "Graficamos el árbol obtenido mediante el uso de plot_tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMkutzNned59"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "plot_tree(clf, filled=True, class_names=True)\n",
    "plt.title(\"Decision tree training for training dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nE6NI7e1eyPr"
   },
   "source": [
    "6. Explore algunos métodos del DecisionTreeClassifier como apply, get_depth, get_n_leaves, para el modelo obtenido. Imprímalos y corrobore su resultado usando el diagrama del árbol. Explique lo que hace cada uno de estos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r0qCM3zAisi"
   },
   "outputs": [],
   "source": [
    "# Aplicar métodos apply, get_depth, get_n_leaves y entender lo que dicen del árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfRCFbaZzxBd"
   },
   "source": [
    "## Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcztccV6y_H-"
   },
   "source": [
    "\n",
    "A continuación, enntrene un árbol de decisión para el conjunto de datos sobre diabetes.\n",
    "\n",
    "7. Entrene un árbol de decisión utilizando el clasificador de SKLearn con un conjunto de entrenamiento del 80% del dataset. Utilice random_state=0 y el criterio de entropía. Grafique el árbol. ¿Cuál es la precisión de este modelo?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVG5qlHSH7GY"
   },
   "outputs": [],
   "source": [
    "## Su código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3I0YkNKOSHb"
   },
   "source": [
    "###  Poda del árbol\n",
    "Uno de los parámetros del DecisionTreeClassifier es *ccp_alpha*, el cual es un parámetro para la poda del árbol mediante el método *Mínimal cost complexity*. El código siguiente arroja una lista de valores de alpha que resultan efectivos en la poda del árbol.\n",
    "\n",
    "Entre mayor es el valor de $\\alpha$, más se poda el árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnCQRsAD0lWi"
   },
   "outputs": [],
   "source": [
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "ccp_alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdzfK6u_vt3B"
   },
   "source": [
    "9. Usando el arreglo de valores de *ccp_alpha* arrojados en la celda anterior, crear un loop que entrene un árbol para cada parámetro de ccp_alpha e imprima su precisión. De esta lista, extraer el valor de ccp_alpha optimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMpB5jff9PDe"
   },
   "outputs": [],
   "source": [
    "## código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh0clgfIzWn9"
   },
   "source": [
    "10. Entrenar un clasificador con el ccp_alpha óptimo. Graficarlo y compararlo con el árbol inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L8s8kKfBv_h"
   },
   "source": [
    "## Árbol de regresión\n",
    "Para éste ejercicio usamos el dataset de Hitters, cuya variable objetivo es el salario, el cual no es una variable categórica. Para esto necesitamos un árbol de regresión, a saber, el algoritmo *DecisionTreeRegressor* de SKLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0vxBx4Nydan"
   },
   "source": [
    "Primero leemos el dataset, y eliminamos los valores faltantes, pues este algoritmo no los maneja. Consideraremosmos como entrada  X únicamente dos de sus variables: Years, Hits. Tomamos como variable objetivo el salario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgBn00RvByaU"
   },
   "outputs": [],
   "source": [
    "# Se lee el dataset y se omiten los registros con valores faltantes.\n",
    "df = pd.read_csv('Hitters.csv').dropna()\n",
    "\n",
    "#Se imprime información sobre dicho dataset.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-3D0numCEch"
   },
   "outputs": [],
   "source": [
    "#Se toman sólo dos de las columnas\n",
    "X = df[['Years', 'Hits']]\n",
    "y = df.Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbDpT0IyzsiS"
   },
   "source": [
    "11. Entrenar un árbol de regresión en X,y con el parámetro max_leaf_nodes=3; usar el método score (coeficiente de determinación) para medir su desempeño, y graficar el árbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGD2Q1OdCKGV"
   },
   "outputs": [],
   "source": [
    "## código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9DzyiqdDcmY"
   },
   "outputs": [],
   "source": [
    "## Graficar el árbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIMxvL770bYG"
   },
   "source": [
    "12. ¿En cuántas regiones $R_i$ separó el espacio de las dos variables de entrada el árbol anterior? Descríbalas.\n",
    "\n",
    "13. Escriba sus conclusiones o preguntas sobre el ejercicio."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
